name: 'FHIR CapabilityStatement Expander'
description: 'Expands FHIR CapabilityStatements by recursively resolving imports and extracts all refer        echo ""
        echo "üìÅ Copied Resources:"
        
        # Then show all other files (copied) - search recursively including subdirectories
        while IFS= read -r -d '' file; do resources'
author: 'Patrick Werner'

branding:
  icon: 'layers'
  color: 'blue'

inputs:
  input_directory:
    description: 'Path to input directory with FHIR JSON files'
    required: true
    default: './input'
  output_directory:
    description: 'Path to output directory for expanded resources'
    required: true
    default: './output'
  capability_statement_url:
    description: 'Canonical URL(s) of the CapabilityStatement(s) to expand. Can be a single URL string or a JSON array of URLs (use toJSON() for YAML lists).'
    required: true
  verbose:
    description: 'Enable verbose logging'
    required: false
    default: 'false'
  python_version:
    description: 'Python version for execution'
    required: false
    default: '3.11'

outputs:
  expanded_files_count:
    description: 'Number of created expanded files'
    value: ${{ steps.expand.outputs.files_count }}
  output_directory:
    description: 'Path to output directory with expanded resources'
    value: ${{ inputs.output_directory }}
  expanded_capability_statement:
    description: 'Filename of the expanded CapabilityStatement'
    value: ${{ steps.expand.outputs.expanded_file }}

runs:
  using: 'composite'
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ inputs.python_version }}
               
    - name: Validate Input Directory
      shell: bash
      run: |
        if [ ! -d "${{ inputs.input_directory }}" ]; then
          echo "‚ùå Input directory not found: ${{ inputs.input_directory }}"
          exit 1
        fi
        
        json_files=$(find "${{ inputs.input_directory }}" -name "*.json" | wc -l)
        echo "‚úÖ Input directory found with $json_files JSON files"
        
        if [ "$json_files" -eq 0 ]; then
          echo "‚ö†Ô∏è  Warning: No JSON files found in input directory"
        fi
        
    - name: Create Output Directory
      shell: bash
      run: |
        mkdir -p "${{ inputs.output_directory }}"
        echo "üìÅ Output directory created: ${{ inputs.output_directory }}"
        
    - name: Run FHIR CapabilityStatement Expander
      id: expand
      shell: bash
      run: |
        # Determine verbose flag - auto-enable when GitHub Actions debug logging is active
        VERBOSE_FLAG=""
        if [ "${{ inputs.verbose }}" = "true" ] || [ "$ACTIONS_STEP_DEBUG" = "true" ]; then
          VERBOSE_FLAG="--verbose"
          if [ "$ACTIONS_STEP_DEBUG" = "true" ]; then
            echo "üîç Auto-enabled verbose logging (GitHub Actions debug mode detected)"
          fi
        fi
        
        # Run the expander
        # Use the environment variable for container compatibility
        SCRIPT_PATH="$GITHUB_ACTION_PATH/capability_statement_expander.py"
        
        if [ -f "$SCRIPT_PATH" ]; then
          echo "‚úÖ Script found, executing..."
          
          # Store capability_statement_url in environment variable to handle multiline JSON
          export CS_URL='${{ inputs.capability_statement_url }}'
          
          # Capture output to extract copied files count
          EXPANDER_OUTPUT=$(python "$SCRIPT_PATH" \
            "${{ inputs.input_directory }}" \
            "${{ inputs.output_directory }}" \
            "$CS_URL" \
            ${{ inputs.verbose == 'true' && '--verbose' || '' }} 2>&1)
          
          echo "$EXPANDER_OUTPUT"
          
          # Extract number of copied files from log output
          copied_files=$(echo "$EXPANDER_OUTPUT" | grep -o '[0-9]\+ files copied' | grep -o '[0-9]\+' || echo "0")
          files_count=$copied_files
          
          echo "files_count=$files_count" >> $GITHUB_OUTPUT
          
          # Find expanded CapabilityStatement file
          expanded_file=$(find "${{ inputs.output_directory }}" -name "*expanded.json" | head -1 | xargs basename 2>/dev/null || echo "")
          echo "expanded_file=$expanded_file" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Capability Statement successfully expanded to ${{ inputs.output_directory }}"
          echo "‚úÖ Successfully processed $files_count files"
          
          # Export output for next step
          echo "EXPANDER_OUTPUT<<EOF" >> $GITHUB_ENV
          echo "$EXPANDER_OUTPUT" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
        else
          echo "‚ùå Script not found at expected location: $SCRIPT_PATH"
          echo "Action path: ${{ github.action_path }}"
          echo "Environment path: $GITHUB_ACTION_PATH"
          exit 1
        fi
        
    - name: List Processed Files
      shell: bash
      run: |
        # Extract the JSON summary from the Python output
        SUMMARY_JSON=$(echo "$EXPANDER_OUTPUT" | sed -n '/FHIR_PROCESSING_SUMMARY_START/,/FHIR_PROCESSING_SUMMARY_END/p' | sed '1d;$d')
        
        if [ -n "$SUMMARY_JSON" ]; then
          echo "üìÑ Processed FHIR Resources:"
          echo "================================"
          
          # Parse totals using simple grep
          expanded_count=$(echo "$SUMMARY_JSON" | grep -o '"total_expanded": [0-9]*' | grep -o '[0-9]*' || echo "0")
          copied_count=$(echo "$SUMMARY_JSON" | grep -o '"total_copied": [0-9]*' | grep -o '[0-9]*' || echo "0")
          total_files=$(echo "$SUMMARY_JSON" | grep -o '"total_files": [0-9]*' | grep -o '[0-9]*' || echo "0")
          
          echo "üîß Expanded Resources:"
          if [ "$expanded_count" -gt 0 ]; then
            # Extract relative_path from expanded_files section
            echo "$SUMMARY_JSON" | sed -n '/"expanded_files"/,/"copied_files"/p' | \
            grep '"relative_path"' | \
            sed 's/.*"relative_path": *"\([^"]*\)".*/  üìã \1/' | \
            while read -r line; do
              # Get size for this file (simplified)
              echo "$line (expanded)"
            done
          else
            echo "  (No expanded resources found)"
          fi
          
          echo ""
          echo "üìÅ Copied Resources:"
          if [ "$copied_count" -gt 0 ]; then
            # Extract from copied_files section - use line-by-line processing
            echo "$SUMMARY_JSON" | sed -n '/"copied_files"/,/"total_expanded"/p' | \
            grep -E '"relative_path"|"resource_type"' | \
            paste - - | \
            sed 's/.*"relative_path": *"\([^"]*\)".*"resource_type": *"\([^"]*\)".*/  üìã \1 [\2]/' || {
              # Simple fallback
              echo "$SUMMARY_JSON" | grep '"relative_path"' | tail -n +2 | \
              sed 's/.*"relative_path": *"\([^"]*\)".*/  üìã \1/'
            }
          else
            echo "  (No copied resources found)"
          fi
          
          echo ""
          echo "================================"
          echo "üìä Summary:"
          echo "  üîß Expanded: $expanded_count files"
          echo "  üìÅ Copied: $copied_count files"
          echo "  üìã Total: $total_files files processed"
        else
          echo "‚ö†Ô∏è  Could not parse processing summary from output"
          echo "Raw output for debugging:"
          echo "$EXPANDER_OUTPUT" | tail -20
        fi
